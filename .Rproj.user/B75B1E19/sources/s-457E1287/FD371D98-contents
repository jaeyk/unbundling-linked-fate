---
title: "Modeling and visualization"
author: "Jae Yeon Kim"
output:
  html_document:
    number_sections: true
    toc: yes
  pdf_document:
    toc: yes
---

## Setup 

```{r}

# Clean up the environment

rm(list = ls())

# Import pacakges 

if (!require("pacman")) install.packages("pacman")
pacman::p_load(
        tidyverse, # for the tidyverse framework
        patchwork, # for arranging ggplots 
        desc, # for descriptive stat analysis
        ggpubr, # for arranging ggplots 
        ggthemes, # for fancy ggplot themes
        broom, # for modeling
        ggfortify, # extended version of ggplot 
        ggsci, # for color palette
        Hmisc, # for capitalization
        rsample, # for bootstrapping 
        purrr, # functional programming tools 
        strapgod, # for bootstrapping
        gmodels, # for confidence intervals 
        interplot, # for visualizing interaction effects
        stargazer, # for model reports  
        conflicted # for resovling conflicts 
        )

conflicted::conflict_prefer("select", "dplyr")
conflicted::conflict_prefer("filter", "dplyr")

```


## Load files

```{r}

# Model evals 

gender_evals <- read_csv("/home/jae/intersectional-bias-in-ml/processed_data/eval_gender_models.csv") 
  
party_id_evals <- read_csv("/home/jae/intersectional-bias-in-ml/processed_data/eval_party_id_models .csv")
  
# Predicted data 
race_predictions <- read_csv("/home/jae/intersectional-bias-in-ml/processed_data/race_predictions.csv")

gender_predictions <- read_csv("/home/jae/intersectional-bias-in-ml/processed_data/gender_predictions.csv")

party_ID_predictions <- read_csv("/home/jae/intersectional-bias-in-ml/processed_data/party_ID_predictions.csv")

```

## Model evals 

```{r}

binded_evals <- bind_rows(gender_evals, party_id_evals) %>%
  select(-X1)

print(xtable::xtable(binded_evals), include.rownames = FALSE)

```

## Merge predicted datasets 

### Merge 

```{r}

# Multi inner join 

# Merge
merged <- bind_cols(
          race_predictions %>% select(text, label, votes, race_bi, race_all, aae_count, wae_count), 
          gender_predictions %>% select(male, female, gender),
          party_ID_predictions %>% select(party_ID)
          )

# Explore the new object 
glimpse(merged)

```


### Check duplicates 

- 8,045 tweets are duplicate. 

```{r}

# Inspect duplicate values 
sum(duplicated(merged$text))

```

```{r}

# Remove duplicate values 
merged <- merged[!duplicated(merged$text), ]

```

## Clean and wrangle data 

```{r}

df <- merged %>% select(-text)

# Recode values 

df <- df %>%
  mutate(race = recode(race_bi, 
                       `1` = "White", 
                       `0` = "African American"),
         party_ID = recode(party_ID, 
                       `1` = "Democrat",
                       `0` = "Republican"),
         label = capitalize(label),
         gender = capitalize(gender))  

# Remove columns
df <- df %>% select(-c("race_all", "race_bi"))

# Convert data type 

df <- df %>%
  # Turn column into factor 
  sapply(as.factor) %>%  
  # Turn a matrix into a dataframe
  as.data.frame()

# Reorder race values 

levels(df$race) <- c("White","African American")

```

## Exploratory data analysis

```{r}

# Crosstabs 

table(df$race)

table(df$race, df$label)

```
- Note that the filtering reduces the data size from 91,950 to 37,560.

```{r}

# Subset 

df <- df %>%
  filter(race %in% c("White", "African American"), 
         gender %in% c("Male", "Female")) 

```

```{r}

# How race interacts with gender

gender_plot <- df %>%
  group_by(race, gender, label) %>%
  dplyr::summarize(n = n()) %>% 
  mutate(prop = n / sum(n),
         prop = round(prop,2)) %>% 
  filter(label %in% c("Abusive", "Normal", "Hateful")) %>%
  unite(race_gender, c("race", "gender")) %>%
  mutate(race_gender = str_replace(race_gender, "_", " ")) %>%
  ggplot(aes(x = race_gender, y = prop, fill = label)) +
    geom_col(position = "fill") +
    labs(title = "How race interacts with gender", 
         y = "Proportion", 
         x = "",
         fill = "Label",
         caption = "Founta et al. 2018 and the authors") +
    theme_pubr() +
    coord_flip() +
    scale_fill_npg()

gender_plot 

ggsave("/home/jae/intersectional-bias-in-ml/outputs/race_gender.png", gender_plot, 
       dpi = 600,
       width = 6,
       height = 4)

```

```{r}

# How race interacts with party ID

party_plot <- df %>%
  group_by(race, party_ID, label) %>%
  dplyr::summarize(n = n()) %>% 
  mutate(prop = n / sum(n),
         prop = round(prop,2)) %>% 
  filter(label %in% c("Abusive", "Normal", "Hateful")) %>%
  unite(race_party, c("race", "party_ID")) %>%
  mutate(race_party = str_replace(race_party, "_", " ")) %>%
  ggplot(aes(x = race_party, y = prop, fill = label)) +
    geom_col(position = "fill") +
    labs(title = "How race interacts with party ID", 
         y = "Proportion", 
         x = "",
         fill = "Label",
         caption = "Founta et al. 2018 and the authors") +
    theme_pubr() +
    coord_flip() +
    scale_fill_npg()

party_plot 

ggsave("/home/jae/intersectional-bias-in-ml/outputs/race_party.png", party_plot,
       dpi = 600,
       width = 6,
       height = 4)

```

```{r}

ggarrange(gender_plot, party_plot, ncol = 1, nrow = 2,
          common.legend = TRUE)

ggsave("/home/jae/intersectional-bias-in-ml/outputs/desc_combined.png", 
       dpi = 600,
       width = 6,
       height = 4)
  
```

## Modeling and visualization

```{r}

# DVs

df <- df %>%
  mutate(hateful = ifelse(label == "Hateful", 1, 0),
         abusive = ifelse(label == "Abusive", 1, 0),
         normal = ifelse(label == "Normal", 1, 0),
         black = ifelse(race == "African American", 1, 0),
         White = ifelse(race != "African American", 1, 0))

```

### Logistic regressions 

#### Categorical variables 

```{r eval=FALSE, include=FALSE}

# Logistic regressions 
hateful_slim <- glm(hateful ~ black + gender + black*gender, family = binomial(link = "logit"), data = df)
  
hateful_out <- glm(hateful ~ black + gender + party_ID + black*gender + White*party_ID, family = binomial(link = "logit"), data = df)

abusive_slim <- glm(abusive ~ black + gender + black*gender, family = binomial(link = "logit"), data = df)
  
abusive_out <- glm(abusive ~ black + gender + party_ID + black*gender + White*party_ID, family = binomial(link = "logit"), data = df)

```

```{r echo=TRUE}
# Summary 

stargazer(hateful_slim, hateful_out)

stargazer(abusive_slim, abusive_out)

```

```{r eval=FALSE, include=FALSE}

# Save model objects

write_rds(hateful_out, "/home/jae/bias-in-ml/twitter/processed_data/hateful_out.rds")
write_rds(abusive_out, "/home/jae/bias-in-ml/twitter/processed_data/abusive_out.rds")

```

```{r eval=FALSE, include=FALSE}

# Tidy model objects 

models_full <- bind_rows(mutate(hateful_out %>% 
  tidy(), Category = "Hateful"),
          mutate(abusive_out %>%
  tidy(), Category = "Abusive"))

models_slim <- bind_rows(mutate(hateful_slim %>% 
  tidy(), Category = "Hateful"),
          mutate(abusive_slim %>%
  tidy(), Category = "Abusive"))

models <- bind_rows(mutate(models_full, Models = "With party controls"),
                    mutate(models_slim, Models = "Without party controls"))

```

```{r eval=FALSE, include=FALSE}

# Function for interpretation 

interpret_estimate <- function(model){
    
    # Control 
    intercept <- model$estimate[model$term == "(Intercept)"]
    control <- exp(intercept) / (1 + exp(intercept))
    
    # Likelihood 
    model <- model %>% filter(term != "(Intercept)")
    
    model$likelihood <- (exp(model$estimate) / (1 - control + (control * exp(model$estimate))))
    
    return(model)
}

```

```{r eval=FALSE, include=FALSE}

interpret_estimate(models) %>%
  filter(term != "(Intercept)") %>%
  mutate(term = gsub("race|party_ID|gender","", term)) %>%
  mutate(term = str_replace_all(term, "black", "African American")) %>% 
  knitr::kable()
  
```

```{r eval=FALSE, include=FALSE}

interpret_estimate(models) %>%
  filter(term != "(Intercept)") %>%
  mutate(term = gsub("race|party_ID|gender","", term)) %>%
  mutate(term = str_replace_all(term, "black", "African American")) %>%
  ggplot(aes(x = fct_reorder(term, likelihood), y = likelihood, ymax = likelihood + 2*std.error, ymin = likelihood - 2*std.error, moe = std.error, color = Models)) +
  scale_color_npg() +
  geom_pointrange() +
  facet_wrap(~Category) +
  coord_flip() +
  labs(y = "Likelihood", x = "",
      title = "Logistic regression analysis",
      caption = "Founta et al (2018) and the authors") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_pubr() 
  
ggsave("/home/jae/intersectional-bias-in-ml/outputs/log_interpreted.png",
       dpi = 600,
       width = 7,
       height = 4)

```

#### Continuous variables 

```{r eval=FALSE, include=FALSE}

# Remove stuff to increase memory 
rm(gender_predictions, party_ID_predictions, race_predictions, merged, abusive_out, hateful_out)

# Subset 
test <- df %>% filter(race == "African American")

test$aae_count <- test$aae_count %>% 
  as.character() %>% 
  as.numeric() %>% 
  round(1) %>%
  as.factor()

```

```{r eval=FALSE, include=FALSE}

hateful_out_aae <- glm(hateful ~ aae_count + gender + party_ID + aae_count*gender + aae_count*party_ID, family = binomial(link = "logit"), data = test)

```

```{r eval=FALSE, include=FALSE}

cont_plot <- interpret_estimate(hateful_out_aae %>% tidy()) %>%
  filter(term != "(Intercept)") %>%
  mutate(term = gsub("race|party_ID|gender","", term)) 
  
```

### T-test with bootstapped samples 

```{r}

# For reproducibility 

set.seed(1234)

# Bootstrapping (with selected sample)

boots <- df %>%
  gather(type, value, c("abusive","hateful","normal")) %>%
  group_by(race, gender) %>%
  bootstrapify(1000) %>%
  group_by(race, gender, type) %>%
  summarise(
    mean = mean(value),
    lowCI = ci(value)[2],
    hiCI = ci(value)[3])

# Wrangle 

boots <- boots %>%
  filter(race %in% c("White", "African American")) %>%
  filter(gender %in% c("Male", "Female")) %>%
  mutate(type = capitalize(type))

```

```{r}

gender_plot_boot <- boots %>%
  unite(race_gender, c("race", "gender")) %>%
  mutate(race_gender = str_replace(race_gender, "_", " ")) %>%
  ggplot(aes(x = type, y = mean, fill = race_gender)) +
    geom_col(position = "dodge") +
    geom_errorbar(aes(ymax = hiCI, ymin = lowCI), position = "dodge") +
    labs(title = "How race interacts with gender (with bootstrapping)", 
         y = "Proportion", 
         x = "",
         fill = "Subgroup",
         caption = "Founta et al. 2018 and the authors") +
    theme_pubr() +
    coord_flip() +
    scale_fill_npg() +
    guides(fill = guide_legend(nrow = 2, byrow = TRUE))

gender_plot_boot

ggsave("/home/jae/intersectional-bias-in-ml/outputs/race_gender_boot.png", gender_plot_boot, 
       dpi = 600,
       width = 6,
       height = 4)

```